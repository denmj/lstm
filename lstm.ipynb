{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing weights and biases...\n",
      "W:  [ 1.7641  0.4002  0.9787  2.2409  1.8676 -0.9773  0.9501 -0.1514]\n",
      "U:  [-0.1032  0.4106  0.144   1.4543  0.761   0.1217  0.4439  0.3337  1.4941 -0.2052  0.3131 -0.8541 -2.553   0.6536  0.8644 -0.7422]\n",
      "b:  [ 2.2698 -1.4544  0.0458 -0.1872  1.5328  1.4694  0.1549  0.3782]\n",
      "h_t before LSTM Forward Pass:  [[0. 0.]]\n",
      "C_t before LSTM Forward Pass:  [[0. 0.]]\n",
      "--------------------------------\n",
      "Starting LSTM Forward Pass...\n",
      "\n",
      "Time step 1, Input: [2]\n",
      "x_t * W:  [[2]]  *  [[ 1.7641  0.4002  0.9787  2.2409  1.8676 -0.9773  0.9501 -0.1514]]  =  [[ 3.5281  0.8003  1.9575  4.4818  3.7351 -1.9546  1.9002 -0.3027]]\n",
      "h_t * U:  [[0. 0.]]  *  [[-0.1032  0.4106  0.144   1.4543  0.761   0.1217  0.4439  0.3337]\n",
      " [ 1.4941 -0.2052  0.3131 -0.8541 -2.553   0.6536  0.8644 -0.7422]]  =  [[0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "  Gates raw values: [ 5.7979 -0.6541  2.0032  4.2946  5.2679 -0.4852  2.0551  0.0754]\n",
      "--------------------------------\n",
      "Input to F gate   [[ 5.7979 -0.6541]]\n",
      "  Forget Gate (f_t): [0.997  0.3421]\n",
      "  Input Gate (i_t): [0.8811 0.9865]\n",
      "  Output Gate (o_t): [0.9949 0.381 ]\n",
      "  Candidate Cell State (C~_t): [0.9677 0.0753]\n",
      "  Updated Cell State (C_t): [0.8527 0.0743]\n",
      "  Updated Hidden State (h_t): [0.6889 0.0283]\n",
      "\n",
      "Time step 2, Input: [4]\n",
      "x_t * W:  [[4]]  *  [[ 1.7641  0.4002  0.9787  2.2409  1.8676 -0.9773  0.9501 -0.1514]]  =  [[ 7.0562  1.6006  3.915   8.9636  7.4702 -3.9091  3.8004 -0.6054]]\n",
      "h_t * U:  [[0.6889 0.0283]]  *  [[-0.1032  0.4106  0.144   1.4543  0.761   0.1217  0.4439  0.3337]\n",
      " [ 1.4941 -0.2052  0.3131 -0.8541 -2.553   0.6536  0.8644 -0.7422]]  =  [[-0.0289  0.2771  0.1081  0.9778  0.4522  0.1023  0.3302  0.2089]]\n",
      "  Gates raw values: [ 9.2971  0.4233  4.0688  9.7541  9.4552 -2.3375  4.2855 -0.0184]\n",
      "--------------------------------\n",
      "Input to F gate   [[9.2971 0.4233]]\n",
      "  Forget Gate (f_t): [0.9999 0.6043]\n",
      "  Input Gate (i_t): [0.9832 0.9999]\n",
      "  Output Gate (o_t): [0.9999 0.0881]\n",
      "  Candidate Cell State (C~_t): [ 0.9996 -0.0184]\n",
      "  Updated Cell State (C_t): [1.8354 0.0265]\n",
      "  Updated Hidden State (h_t): [0.9503 0.0023]\n",
      "\n",
      "Time step 3, Input: [6]\n",
      "x_t * W:  [[6]]  *  [[ 1.7641  0.4002  0.9787  2.2409  1.8676 -0.9773  0.9501 -0.1514]]  =  [[10.5843  2.4009  5.8724 13.4454 11.2053 -5.8637  5.7005 -0.9081]]\n",
      "h_t * U:  [[0.9503 0.0023]]  *  [[-0.1032  0.4106  0.144   1.4543  0.761   0.1217  0.4439  0.3337]\n",
      " [ 1.4941 -0.2052  0.3131 -0.8541 -2.553   0.6536  0.8644 -0.7422]]  =  [[-0.0946  0.3897  0.1376  1.38    0.7172  0.1172  0.4238  0.3154]]\n",
      "  Gates raw values: [12.7595  1.3363  6.0558 14.6381 13.4554 -4.2772  6.2793 -0.2146]\n",
      "--------------------------------\n",
      "Input to F gate   [[12.7595  1.3363]]\n",
      "  Forget Gate (f_t): [1.     0.7919]\n",
      "  Input Gate (i_t): [0.9977 1.    ]\n",
      "  Output Gate (o_t): [1.     0.0137]\n",
      "  Candidate Cell State (C~_t): [ 1.     -0.2114]\n",
      "  Updated Cell State (C_t): [ 2.8331 -0.1904]\n",
      "  Updated Hidden State (h_t): [ 0.9931 -0.0026]\n",
      "\n",
      "LSTM Forward Pass Completed.\n"
     ]
    }
   ],
   "source": [
    "# Redefine the environment after reset\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=200)\n",
    "\n",
    "\n",
    "# Dimensions\n",
    "d = 1  # Input size (1 feature)\n",
    "h = 2  # Hidden size (2 units) -> this is abstract representation of the sequence, bigger dimension means more complex patterns can be learned\n",
    "batch_size = 1  # Batch size (1 sequence)\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(0)\n",
    "W = np.random.randn(d, 4 * h)  # Input weights [d, 4h]\n",
    "U = np.random.randn(h, 4 * h)  # Recurrent weights [h, 4h]\n",
    "b = np.random.randn(1, 4 * h)  # Bias [1, 4h]\n",
    "\n",
    "print(\"Initializing weights and biases...\")\n",
    "print(\"W: \", W.flatten())\n",
    "print(\"U: \", U.flatten())\n",
    "print(\"b: \", b.flatten())\n",
    "\n",
    "# Initialize hidden state and cell state\n",
    "h_t = np.zeros((batch_size, h))  # Hidden state [batch, h]\n",
    "C_t = np.zeros((batch_size, h))  # Cell state [batch, h]\n",
    "\n",
    "# Define single sequence with 1 feature (e.g., [2, 4, 6])\n",
    "X = np.array([[[2], [4], [6]]])  # Shape: [batch, timesteps, features]\n",
    "\n",
    "# Detailed forward pass with print statements for each step\n",
    "print(\"h_t before LSTM Forward Pass: \", h_t)\n",
    "print(\"C_t before LSTM Forward Pass: \", C_t)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "print(\"Starting LSTM Forward Pass...\\n\")\n",
    "\n",
    "for t in range(X.shape[1]):  # Loop through each timestep\n",
    "    print(f\"Time step {t + 1}, Input: {X[:, t, :].flatten()}\")\n",
    "    \n",
    "    x_t = X[:, t, :]  # Input at timestep t [batch, d]\n",
    "\n",
    "    print(\"x_t * W: \", x_t, \" * \", W, \" = \", np.dot(x_t, W))\n",
    "    print(\"h_t * U: \", h_t, \" * \", U, \" = \", np.dot(h_t, U))\n",
    "\n",
    "\n",
    "    gates = np.dot(x_t, W) + np.dot(h_t, U) + b  # [batch, 4h]\n",
    "    print(f\"  Gates raw values: {gates.flatten()}\")\n",
    "    \n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    print(\"Input to F gate  \", gates[:, :h])\n",
    "\n",
    "    f_t = 1 / (1 + np.exp(-gates[:, :h]))  # Forget gate [batch, h]\n",
    "    print(f\"  Forget Gate (f_t): {f_t.flatten()}\")\n",
    "\n",
    "    i_t = 1 / (1 + np.exp(-gates[:, h:2 * h]))  # Input gate [batch, h]\n",
    "    print(f\"  Input Gate (i_t): {i_t.flatten()}\")\n",
    "\n",
    "    o_t = 1 / (1 + np.exp(-gates[:, 2 * h:3 * h]))  # Output gate [batch, h]\n",
    "    print(f\"  Output Gate (o_t): {o_t.flatten()}\")\n",
    "\n",
    "    C_t_candidate = np.tanh(gates[:, 3 * h:])  # Candidate cell state [batch, h]\n",
    "    print(f\"  Candidate Cell State (C~_t): {C_t_candidate.flatten()}\")\n",
    "\n",
    "    # Update cell state\n",
    "    C_t = f_t * C_t + i_t * C_t_candidate  # [batch, h]\n",
    "    print(f\"  Updated Cell State (C_t): {C_t.flatten()}\")\n",
    "\n",
    "    # Update hidden state\n",
    "    h_t = o_t * np.tanh(C_t)  # [batch, h]\n",
    "    print(f\"  Updated Hidden State (h_t): {h_t.flatten()}\\n\")\n",
    "\n",
    "print(\"LSTM Forward Pass Completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define single sequence with 1 feature (e.g., [2, 4, 6])\n",
    "X = np.array([[[2], [4], [6]]])  # Shape: [batch, timesteps, features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2],\n",
       "        [4],\n",
       "        [6]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions\n",
    "d = 1  # Input size (1 feature)\n",
    "h = 2  # Hidden size (2 units)\n",
    "batch_size = 1  # Batch size (1 sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and biases\n",
    "np.random.seed(0)\n",
    "W = np.random.randn(d, 4 * h)  # Input weights [d, 4h]\n",
    "U = np.random.randn(h, 4 * h)  # Recurrent weights [h, 4h]\n",
    "b = np.random.randn(1, 4 * h)  # Bias [1, 4h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hidden state and cell state\n",
    "h_t = np.zeros((batch_size, h))  # Hidden state [batch, h]\n",
    "C_t = np.zeros((batch_size, h))  # Cell state [batch, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At timestep 0 x_t is [[2]]\n",
      "At timestep 0 gates are [[ 5.69150442 -0.24575738  2.14547783  5.74104175  6.03025755 -0.366045\n",
      "   2.49369845  0.40873171]]\n",
      "At timestep 1 x_t is [[4]]\n",
      "At timestep 1 gates are [[ 9.40280444  0.53070912  4.14188673 10.12270543  9.4542689  -2.23990763\n",
      "   4.50152825  0.01594867]]\n",
      "At timestep 2 x_t is [[6]]\n",
      "At timestep 2 gates are [[12.78014531  1.3530555   6.06832762 14.69535743 13.44896222 -4.25985873\n",
      "   6.31616641 -0.2109283 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'x_t': array([2]),\n",
       "  'f_t': array([0.99663684, 0.43886803]),\n",
       "  'i_t': array([0.89524544, 0.99679886]),\n",
       "  'o_t': array([0.9976009 , 0.40949703]),\n",
       "  'C_t_candidate': array([0.98644568, 0.38739526]),\n",
       "  'C_t': array([3.70666547, 0.30260307]),\n",
       "  'h_t': array([0.9963982, 0.1202664])},\n",
       " {'x_t': array([4]),\n",
       "  'f_t': array([0.99991751, 0.62964849]),\n",
       "  'i_t': array([0.98435579, 0.99995984]),\n",
       "  'o_t': array([0.99992165, 0.09622357]),\n",
       "  'C_t_candidate': array([0.99975396, 0.01594732]),\n",
       "  'C_t': array([4.69047333, 0.20648024]),\n",
       "  'h_t': array([0.99975305, 0.01959065])},\n",
       " {'x_t': array([6]),\n",
       "  'f_t': array([0.99999718, 0.79462872]),\n",
       "  'i_t': array([0.99769031, 0.99999959]),\n",
       "  'o_t': array([0.99999856, 0.01392758]),\n",
       "  'C_t_candidate': array([ 0.99999347, -0.20785486]),\n",
       "  'C_t': array([ 5.68814392, -0.04377964]),\n",
       "  'h_t': array([ 9.99975629e-01, -6.09355263e-04])}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for t in range(X.shape[1]):  # Loop through each timestep\n",
    "    x_t = X[:, t, :]  # Input at timestep t [batch, d]\n",
    "    print(\"At timestep\", t, \"x_t is\", x_t)\n",
    "    # Compute gates\n",
    "    gates = np.dot(x_t, W) + np.dot(h_t, U) + b  # [batch, 4h]\n",
    "    print(\"At timestep\", t, \"gates are\", gates)\n",
    "    f_t = 1 / (1 + np.exp(-gates[:, :h]))  # Forget gate [batch, h]\n",
    "    i_t = 1 / (1 + np.exp(-gates[:, h:2 * h]))  # Input gate [batch, h]\n",
    "    o_t = 1 / (1 + np.exp(-gates[:, 2 * h:3 * h]))  # Output gate [batch, h]\n",
    "    C_t_candidate = np.tanh(gates[:, 3 * h:])  # Candidate cell state [batch, h]\n",
    "\n",
    "    # Update cell state\n",
    "    C_t = f_t * C_t + i_t * C_t_candidate  # [batch, h]\n",
    "\n",
    "    # Update hidden state\n",
    "    h_t = o_t * np.tanh(C_t)  # [batch, h]\n",
    "\n",
    "    # Store results for this timestep\n",
    "    results.append({\n",
    "        \"x_t\": x_t.flatten(),\n",
    "        \"f_t\": f_t.flatten(),\n",
    "        \"i_t\": i_t.flatten(),\n",
    "        \"o_t\": o_t.flatten(),\n",
    "        \"C_t_candidate\": C_t_candidate.flatten(),\n",
    "        \"C_t\": C_t.flatten(),\n",
    "        \"h_t\": h_t.flatten(),\n",
    "    })\n",
    "\n",
    "# Display results for each timestep\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
